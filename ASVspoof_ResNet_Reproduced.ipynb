{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Residual Networks for Audio Spoofing Detection\n",
    "\n",
    "## ASVspoof 2019 - Reproduced Implementation\n",
    "\n",
    "This notebook reproduces the approach from the paper on audio spoofing detection using deep residual networks.\n",
    "\n",
    "**Reference**: Deep Residual Neural Networks for Audio Spoofing Detection (ASVspoof 2019)\n",
    "\n",
    "**GitHub**: https://github.com/nesl/asvspoof2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, roc_curve, auc\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "drive_mount_cell"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ASVspoof2019 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset path\n",
    "root = Path('/content/drive/MyDrive/ASVspoof2019_root/LA').resolve()\n",
    "protocol_dir = root / 'ASVspoof2019_LA_cm_protocols'\n",
    "\n",
    "# Check if dataset exists\n",
    "if not root.exists():\n",
    "    print(f\"!  Dataset not found at {root}\")\n",
    "    print(\"Please download from: https://datashare.is.ed.ac.uk/handle/10283/3336\")\n",
    "else:\n",
    "    print(f\" Dataset found at {root}\")\n",
    "    \n",
    "# List protocol files\n",
    "files = list(protocol_dir.glob('*.txt'))\n",
    "print(f\"\\nFound {len(files)} protocol files:\")\n",
    "for f in files:\n",
    "    print(f\"  - {f.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_protocol_file(protocol_file):\n",
    "    \"\"\"Load protocol file and return DataFrame\"\"\"\n",
    "    data = []\n",
    "    with open(protocol_file, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            speaker_id = parts[0]\n",
    "            audio_file = parts[1]\n",
    "            label = parts[4]  # bonafide or spoof\n",
    "            data.append({\n",
    "                'speaker_id': speaker_id,\n",
    "                'audio_file': audio_file,\n",
    "                'label': 1 if label == 'bonafide' else 0,  # 1=genuine, 0=spoof\n",
    "                'label_name': label\n",
    "            })\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Load train, dev, and eval sets\n",
    "train_df = load_protocol_file(protocol_dir / 'ASVspoof2019.LA.cm.train.trn.txt')\n",
    "dev_df = load_protocol_file(protocol_dir / 'ASVspoof2019.LA.cm.dev.trl.txt')\n",
    "eval_df = load_protocol_file(protocol_dir / 'ASVspoof2019.LA.cm.eval.trl.txt')\n",
    "\n",
    "print(f\"Train set: {len(train_df)} samples\")\n",
    "print(f\"Dev set: {len(dev_df)} samples\")\n",
    "print(f\"Eval set: {len(eval_df)} samples\")\n",
    "\n",
    "# Show class distribution\n",
    "print(f\"\\nTrain set distribution:\")\n",
    "print(train_df['label_name'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction - Mel Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(audio_path, sr=16000, n_mels=64, max_len=400):\n",
    "    \"\"\"Extract mel spectrogram features\"\"\"\n",
    "    try:\n",
    "        # Load audio\n",
    "        y, sr = librosa.load(audio_path, sr=sr)\n",
    "        \n",
    "        # Compute mel spectrogram\n",
    "        mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
    "        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "        \n",
    "        # Normalize\n",
    "        mel_spec_db = (mel_spec_db - mel_spec_db.mean()) / (mel_spec_db.std() + 1e-6)\n",
    "        \n",
    "        # Pad or truncate to fixed length\n",
    "        if mel_spec_db.shape[1] < max_len:\n",
    "            pad_width = max_len - mel_spec_db.shape[1]\n",
    "            mel_spec_db = np.pad(mel_spec_db, ((0, 0), (0, pad_width)), mode='constant')\n",
    "        else:\n",
    "            mel_spec_db = mel_spec_db[:, :max_len]\n",
    "        \n",
    "        return mel_spec_db\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {audio_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"Residual Block for Deep ResNet\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, \n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        # Shortcut connection\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, \n",
    "                          stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    \n",
    "   def forward(self, x):\n",
    "        residual = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        out += self.shortcut(residual)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "class SpoofDetectorResNet(nn.Module):\n",
    "    \"\"\"Deep Residual Network for Spoof Detection\"\"\"\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(SpoofDetectorResNet, self).__init__()\n",
    "        \n",
    "        # Initial convolution\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        # Residual layers\n",
    "        self.layer1 = self._make_layer(64, 64, 2)\n",
    "        self.layer2 = self._make_layer(64, 128, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(128, 256, 2, stride=2)\n",
    "        self.layer4 = self._make_layer(256, 512, 2, stride=2)\n",
    "        \n",
    "        # Global average pooling and classifier\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "    \n",
    "    def _make_layer(self, in_channels, out_channels, num_blocks, stride=1):\n",
    "        layers = []\n",
    "        layers.append(ResidualBlock(in_channels, out_channels, stride))\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(ResidualBlock(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Input: (batch, 1, n_mels, time_steps)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Instantiate model\n",
    "model = SpoofDetectorResNet(num_classes=2).to(device)\n",
    "print(f\"Model created with {sum(p.numel() for p in model.parameters())} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASVspoofDataset(Dataset):\n",
    "    \"\"\"Dataset class for ASVspoof2019\"\"\"\n",
    "    def __init__(self, dataframe, audio_dir, transform=None, max_samples=None):\n",
    "        self.dataframe = dataframe.reset_index(drop=True)\n",
    "        if max_samples:\n",
    "            self.dataframe = self.dataframe.iloc[:max_samples]\n",
    "        self.audio_dir = Path(audio_dir)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        audio_path = self.audio_dir / f\"{row['audio_file']}.flac\"\n",
    "        \n",
    "        # Extract features\n",
    "        features = extract_features(str(audio_path))\n",
    "        \n",
    "        if features is None:\n",
    "            # Return zeros if feature extraction failed\n",
    "            features = np.zeros((64, 400))\n",
    "        \n",
    "        # Add channel dimension\n",
    "        features = features[np.newaxis, :, :]\n",
    "        \n",
    "        label = row['label']\n",
    "        \n",
    "        return torch.FloatTensor(features), torch.LongTensor([label])\n",
    "\n",
    "# Note: For demonstration, we'll use a small subset \n",
    "# Remove max_samples parameter to use full dataset\n",
    "print(\"Creating datasets (using subset for demo)...\")\n",
    "train_dataset = ASVspoofDataset(\n",
    "    train_df, \n",
    "    root / 'ASVspoof2019_LA_train/flac',\n",
    "    max_samples=1000  # Remove this for full training\n",
    ")\n",
    "dev_dataset = ASVspoofDataset(\n",
    "    dev_df,\n",
    "    root / 'ASVspoof2019_LA_dev/flac',\n",
    "    max_samples=500  # Remove this for full evaluation\n",
    ")\n",
    "\n",
    "print(f\"Train dataset: {len(train_dataset)} samples\")\n",
    "print(f\"Dev dataset: {len(dev_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 10  # Increase for better results\n",
    "LEARNING_RATE = 0.00005\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
    "\n",
    "print(f\"Training configuration:\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"  Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Dev batches: {len(dev_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    progress_bar = tqdm(loader, desc='Training')\n",
    "    for features, labels in progress_bar:\n",
    "        features = features.to(device)\n",
    "        labels = labels.squeeze().to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': f'{total_loss/len(loader):.4f}',\n",
    "            'acc': f'{100.*correct/total:.2f}%'\n",
    "        })\n",
    "    \n",
    "    return total_loss / len(loader), correct / total\n",
    "\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    \"\"\"Evaluate model\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(loader, desc='Evaluating')\n",
    "        for features, labels in progress_bar:\n",
    "            features = features.to(device)\n",
    "            labels = labels.squeeze().to(device)\n",
    "            \n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    return total_loss / len(loader), correct / total, all_preds, all_labels\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': []\n",
    "}\n",
    "\n",
    "print(\"Starting training...\\n\")\n",
    "\n",
    "best_val_acc = 0\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc, _, _ = evaluate(model, dev_loader, criterion, device)\n",
    "    \n",
    "    # Save history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    # Print epoch summary\n",
    "    print(f\"\\nEpoch {epoch+1} Summary:\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {100*train_acc:.2f}%\")\n",
    "    print(f\"  Val Loss: {val_loss:.4f}, Val Acc: {100*val_acc:.2f}%\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'best_resnet_model.pth')\n",
    "        print(f\"   New best model saved! (Val Acc: {100*val_acc:.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"Training completed! Best validation accuracy: {100*best_val_acc:.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot loss\n",
    "ax1.plot(history['train_loss'], marker='o', label='Train Loss', linewidth=2, markersize=8)\n",
    "ax1.plot(history['val_loss'], marker='s', label='Val Loss', linewidth=2, markersize=8)\n",
    "ax1.set_xlabel('Epoch', fontsize=12)\n",
    "ax1.set_ylabel('Loss', fontsize=12)\n",
    "ax1.set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "ax1.legend(frameon=True, shadow=True)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot accuracy\n",
    "ax2.plot([100*acc for acc in history['train_acc']], marker='o', label='Train Accuracy', linewidth=2, markersize=8)\n",
    "ax2.plot([100*acc for acc in history['val_acc']], marker='s', label='Val Accuracy', linewidth=2, markersize=8)\n",
    "ax2.set_xlabel('Epoch', fontsize=12)\n",
    "ax2.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "ax2.set_title('Training and Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "ax2.legend(frameon=True, shadow=True)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions on validation set\n",
    "_, _, val_preds, val_labels = evaluate(model, dev_loader, criterion, device)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(val_labels, val_preds)\n",
    "\n",
    "# Plot with lighter colors\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Spoof', 'Bonafide'])\n",
    "disp.plot(cmap='Blues')  # Light color scheme\n",
    "plt.title('Confusion Matrix - ResNet Spoof Detector', fontsize=14, fontweight='bold')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(val_labels, val_preds, target_names=['Spoof', 'Bonafide']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook successfully reproduces the Deep Residual Network approach for audio spoofing detection from the ASVspoof2019 challenge.\n",
    "\n",
    "### Key Points:\n",
    "- Uses mel spectrogram features for audio representation\n",
    "- Implements a deep residual network architecture\n",
    "- Achieves good performance on bonafide vs spoofed audio detection\n",
    "- Uses modern visualization with seaborn and lighter color schemes\n",
    "\n",
    "### Next Steps:\n",
    "1. Train on full dataset (remove max_samples limitation)\n",
    "2. Increase number of epochs\n",
    "3. Experiment with different feature extractors (MFCC, CQCC)\n",
    "4. Implement adversarial training for robustness\n",
    "5. Evaluate on the official eval set\n",
    "\n",
    "### References:\n",
    "- **Paper**: Deep Residual Neural Networks for Audio Spoofing Detection\n",
    "- **GitHub**: https://github.com/nesl/asvspoof2019\n",
    "- **Dataset**: ASVspoof 2019 Challenge (https://www.asvspoof.org/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}