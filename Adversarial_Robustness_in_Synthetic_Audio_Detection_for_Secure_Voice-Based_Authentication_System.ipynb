{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cf65c4b-0f70-4a5f-b4cb-8952f9bce589",
   "metadata": {},
   "source": [
    "This notebook details the implementation of a robust synthetic audio detection system, focusing on its resilience against adversarial attacks. We will explore the vulnerabilities of state-of-the-art self-supervised learning (SSL) models (Wav2Vec2, WavLM) and a CNN baseline (ResNet) to various adversarial attacks and subsequently harden these models using adversarial training and other defense mechanisms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c140f4-ac11-401e-8f35-2ef1756c1497",
   "metadata": {},
   "source": [
    "# Library Installation and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ffd66f-2140-4a52-9daa-9af70569a409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install core deep learning and audio processing libraries\n",
    "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113 \n",
    "!pip install transformers datasets librosa soundfile matplotlib seaborn pandas numpy scikit-learn\n",
    "\n",
    "\n",
    "# For system utilities (if not already present, e.g., in a non-Colab env)\n",
    "#!sudo apt-get update && sudo apt-get install -y sox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d31eea-1a97-41a3-b800-879b3ca610be",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchattacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97efa164-7c49-4485-b89a-dbc3b37b9e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchaudio\n",
    "from transformers import AutoFeatureExtractor, AutoModelForSequenceClassification, Wav2Vec2ForSequenceClassification, WavLMForSequenceClassification\n",
    "import librosa\n",
    "\n",
    "# For adversarial attacks\n",
    "import torchattacks as ta\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # Suppress warnings for cleaner output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658a9587-f75d-4afa-a63e-b06b31fb8a46",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "We will use the ASVspoof 2019 Logical Access (LA) dataset as our primary benchmark. The dataset structure needs to be navigated to load the audio files and their corresponding labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04205978-3503-467b-be16-8a65eddcefbe",
   "metadata": {},
   "source": [
    "We will focus on the LA (Logical Access) subset, specifically the train, dev, and eval sets. The ASVspoof2019_LA_cm_protocols directory contains txt files that map audio filenames to their labels (bona fide or spoof)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d16ea41-9c70-4fcb-85cc-0af90e7f1e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASVspoof2019_root\n",
    "├── LA\n",
    "│   ├── ASVspoof2019_LA_asv_protocols\n",
    "│   ├── ASVspoof2019_LA_asv_scores\n",
    "│   ├── ASVspoof2019_LA_cm_protocols\n",
    "│   ├── ASVspoof2019_LA_dev\n",
    "│   ├── ASVspoof2019_LA_eval\n",
    "│   ├── ASVspoof2019_LA_train\n",
    "│   └── README.LA.txt\n",
    "└── PA\n",
    "    ├── ASVspoof2019_PA_asv_protocols\n",
    "    ├── ASVspoof2019_PA_asv_scores\n",
    "    ├── ASVspoof2019_PA_cm_protocols\n",
    "    ├── ASVspoof2019_PA_dev\n",
    "    ├── ASVspoof2019_PA_eval\n",
    "    ├── ASVspoof2019_PA_train\n",
    "    └── README.PA.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d609f90-041a-4bbc-ad05-745a53d6a63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the root directory of your ASVspoof 2019 dataset\n",
    "ASVSPOOF_ROOT_LA = 'ASVspoof2019_root/LA'\n",
    "# Define the root directory of your ASVspoof 2019 dataset\n",
    "ASVSPOOF_ROOT_PA = 'ASVspoof2019_root/PA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c50cee79-6e7f-45d0-967a-2a86d8038f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Paths to LA protocol files\n",
    "TRAIN_PROTOCOL_LA = os.path.join(ASVSPOOF_ROOT_LA, 'ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.train.trn.txt')\n",
    "DEV_PROTOCOL_LA = os.path.join(ASVSPOOF_ROOT_LA, 'ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.dev.trl.txt')\n",
    "EVAL_PROTOCOL_LA = os.path.join(ASVSPOOF_ROOT_LA, 'ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.eval.trl.txt')\n",
    "\n",
    "# Paths to LA audio directories\n",
    "TRAIN_AUDIO_DIR_LA = os.path.join(ASVSPOOF_ROOT_LA, 'ASVspoof2019_LA_train/flac')\n",
    "DEV_AUDIO_DIR_LA = os.path.join(ASVSPOOF_ROOT_LA, 'ASVspoof2019_LA_dev/flac')\n",
    "EVAL_AUDIO_DIR_LA = os.path.join(ASVSPOOF_ROOT_LA, 'ASVspoof2019_LA_eval/flac')\n",
    "\n",
    "# Paths to PA protocol files\n",
    "TRAIN_PROTOCOL_PA = os.path.join(ASVSPOOF_ROOT_PA, 'ASVspoof2019_PA_cm_protocols/ASVspoof2019.PA.cm.train.trn.txt')\n",
    "DEV_PROTOCOL_PA = os.path.join(ASVSPOOF_ROOT_PA, 'ASVspoof2019_PA_cm_protocols/ASVspoof2019.PA.cm.dev.trl.txt')\n",
    "EVAL_PROTOCOL_PA = os.path.join(ASVSPOOF_ROOT_PA, 'ASVspoof2019_PA_cm_protocols/ASVspoof2019.PA.cm.eval.trl.txt')\n",
    "\n",
    "# Paths to PA audio directories\n",
    "TRAIN_AUDIO_DIR_PA = os.path.join(ASVSPOOF_ROOT_PA, 'ASVspoof2019_PA_train/flac')\n",
    "DEV_AUDIO_DIR_PA = os.path.join(ASVSPOOF_ROOT_PA, 'ASVspoof2019_PA_dev/flac')\n",
    "EVAL_AUDIO_DIR_PA = os.path.join(ASVSPOOF_ROOT_PA, 'ASVspoof2019_PA_eval/flac')\n",
    "\n",
    "def load_protocol_file(protocol_path, audio_dir):\n",
    "    \"\"\"\n",
    "    Loads an ASVspoof protocol file and returns a DataFrame.\n",
    "    Each row will contain the full path to the audio file and its label.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(protocol_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(' ')\n",
    "            # Assuming the format: speaker_id filename_id - - attack_type label\n",
    "            # Example: LA_0069 LA_T_1000000 - - A01 bona_fide\n",
    "            # We need filename_id and label\n",
    "            filename_id = parts[1]\n",
    "            label = 1 if parts[-1] == 'bonafide' else 0 # 1 for bonafide, 0 for spoof\n",
    "            full_path = os.path.join(audio_dir, filename_id + '.flac')\n",
    "            data.append({'filepath': full_path, 'label': label})\n",
    "    return pd.DataFrame(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b35d36db-f6bd-4bd5-a055-1cf6075925ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LA training data...\n",
      "Training samples: 25380\n"
     ]
    }
   ],
   "source": [
    "# Load dataframes for train, dev, and eval sets\n",
    "print(\"Loading LA training data...\")\n",
    "train_df_LA = load_protocol_file(TRAIN_PROTOCOL_LA, TRAIN_AUDIO_DIR_LA)\n",
    "print(f\"Training samples: {len(train_df_LA)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "06507c49-cf14-4a3c-bbe1-2e102c032d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASVspoof2019_root/LA\\ASVspoof2019_LA_train/fla...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASVspoof2019_root/LA\\ASVspoof2019_LA_train/fla...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASVspoof2019_root/LA\\ASVspoof2019_LA_train/fla...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASVspoof2019_root/LA\\ASVspoof2019_LA_train/fla...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASVspoof2019_root/LA\\ASVspoof2019_LA_train/fla...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filepath  label\n",
       "0  ASVspoof2019_root/LA\\ASVspoof2019_LA_train/fla...      1\n",
       "1  ASVspoof2019_root/LA\\ASVspoof2019_LA_train/fla...      1\n",
       "2  ASVspoof2019_root/LA\\ASVspoof2019_LA_train/fla...      1\n",
       "3  ASVspoof2019_root/LA\\ASVspoof2019_LA_train/fla...      1\n",
       "4  ASVspoof2019_root/LA\\ASVspoof2019_LA_train/fla...      1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_LA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "18b52d2d-c1c6-4a0f-8467-f8b2783ebb79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PA training data...\n",
      "Training samples: 54000\n"
     ]
    }
   ],
   "source": [
    "# Load dataframes for train, dev, and eval sets\n",
    "print(\"Loading PA training data...\")\n",
    "train_df_PA = load_protocol_file(TRAIN_PROTOCOL_PA, TRAIN_AUDIO_DIR_PA)\n",
    "print(f\"Training samples: {len(train_df_PA)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0aa04c4d-59f4-4141-a6ee-e7be12ce457f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASVspoof2019_root/PA\\ASVspoof2019_PA_train/fla...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASVspoof2019_root/PA\\ASVspoof2019_PA_train/fla...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASVspoof2019_root/PA\\ASVspoof2019_PA_train/fla...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASVspoof2019_root/PA\\ASVspoof2019_PA_train/fla...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASVspoof2019_root/PA\\ASVspoof2019_PA_train/fla...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filepath  label\n",
       "0  ASVspoof2019_root/PA\\ASVspoof2019_PA_train/fla...      1\n",
       "1  ASVspoof2019_root/PA\\ASVspoof2019_PA_train/fla...      1\n",
       "2  ASVspoof2019_root/PA\\ASVspoof2019_PA_train/fla...      1\n",
       "3  ASVspoof2019_root/PA\\ASVspoof2019_PA_train/fla...      1\n",
       "4  ASVspoof2019_root/PA\\ASVspoof2019_PA_train/fla...      1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_PA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a5dbf75-a978-4220-bc4c-32062d9fb01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LA development data...\n",
      "Development samples: 24844\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading LA development data...\")\n",
    "dev_df_LA = load_protocol_file(DEV_PROTOCOL_LA, DEV_AUDIO_DIR_LA)\n",
    "print(f\"Development samples: {len(dev_df_LA)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "71796f1a-8b39-4ba9-b1c0-d417ba8c1bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASVspoof2019_root/LA\\ASVspoof2019_LA_dev/flac\\...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASVspoof2019_root/LA\\ASVspoof2019_LA_dev/flac\\...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASVspoof2019_root/LA\\ASVspoof2019_LA_dev/flac\\...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASVspoof2019_root/LA\\ASVspoof2019_LA_dev/flac\\...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASVspoof2019_root/LA\\ASVspoof2019_LA_dev/flac\\...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filepath  label\n",
       "0  ASVspoof2019_root/LA\\ASVspoof2019_LA_dev/flac\\...      1\n",
       "1  ASVspoof2019_root/LA\\ASVspoof2019_LA_dev/flac\\...      1\n",
       "2  ASVspoof2019_root/LA\\ASVspoof2019_LA_dev/flac\\...      1\n",
       "3  ASVspoof2019_root/LA\\ASVspoof2019_LA_dev/flac\\...      1\n",
       "4  ASVspoof2019_root/LA\\ASVspoof2019_LA_dev/flac\\...      1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df_LA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "73933cf9-1b9b-4240-bf54-28aff0ec06c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PA development data...\n",
      "Development samples: 29700\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading PA development data...\")\n",
    "dev_df_PA = load_protocol_file(DEV_PROTOCOL_PA, DEV_AUDIO_DIR_PA)\n",
    "print(f\"Development samples: {len(dev_df_PA)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b505aaa7-77bf-4f23-b0f8-87f8bc11453e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASVspoof2019_root/PA\\ASVspoof2019_PA_dev/flac\\...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASVspoof2019_root/PA\\ASVspoof2019_PA_dev/flac\\...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASVspoof2019_root/PA\\ASVspoof2019_PA_dev/flac\\...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASVspoof2019_root/PA\\ASVspoof2019_PA_dev/flac\\...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASVspoof2019_root/PA\\ASVspoof2019_PA_dev/flac\\...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filepath  label\n",
       "0  ASVspoof2019_root/PA\\ASVspoof2019_PA_dev/flac\\...      1\n",
       "1  ASVspoof2019_root/PA\\ASVspoof2019_PA_dev/flac\\...      1\n",
       "2  ASVspoof2019_root/PA\\ASVspoof2019_PA_dev/flac\\...      1\n",
       "3  ASVspoof2019_root/PA\\ASVspoof2019_PA_dev/flac\\...      1\n",
       "4  ASVspoof2019_root/PA\\ASVspoof2019_PA_dev/flac\\...      1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df_PA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "11010266-7c22-4cd6-ac39-d0ab1c7e8f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LA evaluation data...\n",
      "Evaluation samples: 71237\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading LA evaluation data...\")\n",
    "eval_df_LA = load_protocol_file(EVAL_PROTOCOL_LA, EVAL_AUDIO_DIR_LA)\n",
    "print(f\"Evaluation samples: {len(eval_df_LA)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "12647564-f609-4aad-b01e-7f7421073389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASVspoof2019_root/LA\\ASVspoof2019_LA_eval/flac...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASVspoof2019_root/LA\\ASVspoof2019_LA_eval/flac...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASVspoof2019_root/LA\\ASVspoof2019_LA_eval/flac...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASVspoof2019_root/LA\\ASVspoof2019_LA_eval/flac...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASVspoof2019_root/LA\\ASVspoof2019_LA_eval/flac...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filepath  label\n",
       "0  ASVspoof2019_root/LA\\ASVspoof2019_LA_eval/flac...      0\n",
       "1  ASVspoof2019_root/LA\\ASVspoof2019_LA_eval/flac...      0\n",
       "2  ASVspoof2019_root/LA\\ASVspoof2019_LA_eval/flac...      0\n",
       "3  ASVspoof2019_root/LA\\ASVspoof2019_LA_eval/flac...      0\n",
       "4  ASVspoof2019_root/LA\\ASVspoof2019_LA_eval/flac...      0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df_LA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3ccb8ee2-c2dc-4faa-873d-22b938e2b9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PA evaluation data...\n",
      "Evaluation samples: 134730\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading PA evaluation data...\")\n",
    "eval_df_PA = load_protocol_file(EVAL_PROTOCOL_PA, EVAL_AUDIO_DIR_PA)\n",
    "print(f\"Evaluation samples: {len(eval_df_PA)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "98eacc34-eebb-4a06-88a0-17dc6e8c3c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASVspoof2019_root/PA\\ASVspoof2019_PA_eval/flac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASVspoof2019_root/PA\\ASVspoof2019_PA_eval/flac...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASVspoof2019_root/PA\\ASVspoof2019_PA_eval/flac...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASVspoof2019_root/PA\\ASVspoof2019_PA_eval/flac...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASVspoof2019_root/PA\\ASVspoof2019_PA_eval/flac...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filepath  label\n",
       "0  ASVspoof2019_root/PA\\ASVspoof2019_PA_eval/flac...      1\n",
       "1  ASVspoof2019_root/PA\\ASVspoof2019_PA_eval/flac...      0\n",
       "2  ASVspoof2019_root/PA\\ASVspoof2019_PA_eval/flac...      0\n",
       "3  ASVspoof2019_root/PA\\ASVspoof2019_PA_eval/flac...      0\n",
       "4  ASVspoof2019_root/PA\\ASVspoof2019_PA_eval/flac...      0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df_PA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "32fdac35-6069-4261-b144-caddf1830b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples loaded: 339891\n",
      "\n",
      "Sample of loaded data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASVspoof2019_root/LA\\ASVspoof2019_LA_train/fla...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASVspoof2019_root/LA\\ASVspoof2019_LA_train/fla...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASVspoof2019_root/LA\\ASVspoof2019_LA_train/fla...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASVspoof2019_root/LA\\ASVspoof2019_LA_train/fla...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASVspoof2019_root/LA\\ASVspoof2019_LA_train/fla...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filepath  label\n",
       "0  ASVspoof2019_root/LA\\ASVspoof2019_LA_train/fla...      1\n",
       "1  ASVspoof2019_root/LA\\ASVspoof2019_LA_train/fla...      1\n",
       "2  ASVspoof2019_root/LA\\ASVspoof2019_LA_train/fla...      1\n",
       "3  ASVspoof2019_root/LA\\ASVspoof2019_LA_train/fla...      1\n",
       "4  ASVspoof2019_root/LA\\ASVspoof2019_LA_train/fla...      1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Concatenate all data for initial exploration and consistent preprocessing\n",
    "full_df = pd.concat([train_df_LA, dev_df_LA, eval_df_LA,train_df_PA, dev_df_PA, eval_df_PA], ignore_index=True)\n",
    "print(f\"Total samples loaded: {len(full_df)}\")\n",
    "\n",
    "# Display a sample of the dataframe\n",
    "print(\"\\nSample of loaded data:\")\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495110b1-107f-4358-a5c6-50fea3c7029c",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "Understanding the dataset is crucial. We'll look at the distribution of bona fide vs. spoof samples, audio lengths, and visualize some spectrograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3c861b74-afd2-421c-8067-7dc97c5140e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    298518\n",
      "1     41373\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Calculating audio lengths (this might take a few minutes)...\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# This can be time-consuming for large datasets, consider sampling\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCalculating audio lengths (this might take a few minutes)...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, row \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfull_df\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterrows\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfull_df\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m: \u001b[38;5;66;03m# Sample for speed\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     19\u001b[0m         y, sr \u001b[38;5;241m=\u001b[39m torchaudio\u001b[38;5;241m.\u001b[39mload(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilepath\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\notebook.py:234\u001b[0m, in \u001b[0;36mtqdm_notebook.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    232\u001b[0m unit_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    233\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;241m*\u001b[39m unit_scale \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal\n\u001b[1;32m--> 234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_printer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mncols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer\u001b[38;5;241m.\u001b[39mpbar \u001b[38;5;241m=\u001b[39m proxy(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\notebook.py:108\u001b[0m, in \u001b[0;36mtqdm_notebook.status_printer\u001b[1;34m(_, total, desc, ncols)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Fallback to text bar if there's no total\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# DEPRECATED: replaced with an 'info' style bar\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# if not total:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# Prepare IPython progress bar\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m IProgress \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# #187 #451 #558 #872\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(WARN_NOIPYW)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total:\n\u001b[0;32m    110\u001b[0m     pbar \u001b[38;5;241m=\u001b[39m IProgress(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39mtotal)\n",
      "\u001b[1;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "# Label distribution\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='label', data=full_df)\n",
    "plt.title('Distribution of Bona Fide (1) vs. Spoof (0) Samples')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(ticks=[0, 1], labels=['Spoof', 'Bona Fide'])\n",
    "plt.show()\n",
    "print(full_df['label'].value_counts())\n",
    "\n",
    "# Audio length distribution\n",
    "audio_lengths = []\n",
    "sample_rate = 16000 # Standard sampling rate for ASVspoof 2019\n",
    "\n",
    "# This can be time-consuming for large datasets, consider sampling\n",
    "print(\"\\nCalculating audio lengths (this might take a few minutes)...\")\n",
    "for i, row in tqdm(full_df.sample(min(10000, len(full_df))).iterrows(), total=min(10000, len(full_df))): # Sample for speed\n",
    "    try:\n",
    "        y, sr = torchaudio.load(row['filepath'])\n",
    "        audio_lengths.append(y.shape[1] / sr)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {row['filepath']}: {e}\")\n",
    "        audio_lengths.append(0) # Append 0 or NaN for failed loads\n",
    "\n",
    "audio_lengths = np.array(audio_lengths)\n",
    "audio_lengths = audio_lengths[audio_lengths > 0] # Filter out failed loads\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(audio_lengths, bins=50, kde=True)\n",
    "plt.title('Distribution of Audio File Durations (seconds)')\n",
    "plt.xlabel('Duration (seconds)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Min audio length: {np.min(audio_lengths):.2f}s\")\n",
    "print(f\"Max audio length: {np.max(audio_lengths):.2f}s\")\n",
    "print(f\"Mean audio length: {np.mean(audio_lengths):.2f}s\")\n",
    "print(f\"Median audio length: {np.median(audio_lengths):.2f}s\")\n",
    "\n",
    "# Visualize a few spectrograms\n",
    "print(\"\\nVisualizing Spectrograms:\")\n",
    "def plot_spectrogram(filepath, title):\n",
    "    try:\n",
    "        waveform, sample_rate = torchaudio.load(filepath)\n",
    "        # Convert to mono if stereo\n",
    "        if waveform.shape[0] > 1:\n",
    "            waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "        \n",
    "        # Compute Mel spectrogram\n",
    "        # n_mels=80 and n_fft=400 (for 25ms window at 16kHz) are common for speech\n",
    "        mel_spectrogram_transform = torchaudio.transforms.MelSpectrogram(\n",
    "            sample_rate=sample_rate,\n",
    "            n_fft=400,\n",
    "            hop_length=160, # 10ms hop\n",
    "            n_mels=80\n",
    "        )\n",
    "        mel_spectrogram = mel_spectrogram_transform(waveform)\n",
    "        mel_spectrogram_db = torchaudio.transforms.AmplitudeToDB()(mel_spectrogram)\n",
    "\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.imshow(mel_spectrogram_db.squeeze().log().cpu().numpy(), origin='lower', aspect='auto', cmap='viridis')\n",
    "        plt.colorbar(format='%+2.0f dB')\n",
    "        plt.title(title)\n",
    "        plt.xlabel('Time Frame')\n",
    "        plt.ylabel('Mel Filter Bank')\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Could not plot spectrogram for {filepath}: {e}\")\n",
    "\n",
    "# Get a random bona fide and a random spoof sample\n",
    "bona_fide_sample = full_df[full_df['label'] == 1].sample(1)['filepath'].iloc[0]\n",
    "spoof_sample = full_df[full_df['label'] == 0].sample(1)['filepath'].iloc[0]\n",
    "\n",
    "plot_spectrogram(bona_fide_sample, 'Bona Fide Audio Spectrogram')\n",
    "plot_spectrogram(spoof_sample, 'Spoof Audio Spectrogram')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e912a17d-6112-4e2a-a117-2fc69be965a2",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "Based on the proposal, audio files need to be standardized (mono, 16-bit PCM WAV, 16kHz sampling rate) and segmented into fixed-length chunks. We'll implement a custom PyTorch Dataset for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc80c81e-1a66-4f15-924b-7a4bd519bf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_SAMPLE_RATE = 16000\n",
    "CHUNK_LENGTH_SEC = 4 # As specified in the proposal\n",
    "MAX_AUDIO_LENGTH = CHUNK_LENGTH_SEC * TARGET_SAMPLE_RATE # Max samples per chunk\n",
    "\n",
    "class AudioSpoofDataset(Dataset):\n",
    "    def __init__(self, dataframe, feature_extractor, max_length=MAX_AUDIO_LENGTH, sample_rate=TARGET_SAMPLE_RATE):\n",
    "        self.dataframe = dataframe\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.max_length = max_length\n",
    "        self.sample_rate = sample_rate\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filepath = self.dataframe.iloc[idx]['filepath']\n",
    "        label = self.dataframe.iloc[idx]['label']\n",
    "\n",
    "        try:\n",
    "            waveform, sr = torchaudio.load(filepath)\n",
    "\n",
    "            # Resample if necessary\n",
    "            if sr != self.sample_rate:\n",
    "                resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=self.sample_rate)\n",
    "                waveform = resampler(waveform)\n",
    "\n",
    "            # Convert to mono\n",
    "            if waveform.shape[0] > 1:\n",
    "                waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "\n",
    "            # Pad or truncate to max_length\n",
    "            if waveform.shape[1] < self.max_length:\n",
    "                padding = self.max_length - waveform.shape[1]\n",
    "                waveform = torch.nn.functional.pad(waveform, (0, padding))\n",
    "            else:\n",
    "                waveform = waveform[:, :self.max_length] # Take the first N samples\n",
    "\n",
    "            # Feature extraction (e.g., for Wav2Vec2/WavLM, this means batching the raw waveform)\n",
    "            # The feature_extractor from transformers handles normalization\n",
    "            inputs = self.feature_extractor(\n",
    "                waveform.squeeze(0).numpy(), # Squeeze to 1D numpy array for feature_extractor\n",
    "                sampling_rate=self.sample_rate,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=\"max_length\", # ensure consistent length for batching\n",
    "                max_length=self.max_length\n",
    "            )\n",
    "\n",
    "            # inputs will contain 'input_values' (raw waveform converted to features for the model)\n",
    "            # and potentially 'attention_mask'\n",
    "            return {'input_values': inputs['input_values'].squeeze(0), 'labels': torch.tensor(label, dtype=torch.long)}\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filepath}: {e}. Skipping this sample.\")\n",
    "            # Return a placeholder or raise an error depending on desired behavior\n",
    "            # For simplicity, returning a dummy tensor here, but in a real scenario, you might filter these out\n",
    "            return {'input_values': torch.zeros(self.max_length), 'labels': torch.tensor(-1, dtype=torch.long)} # Dummy invalid\n",
    "            \n",
    "# Instantiate a feature extractor (e.g., for Wav2Vec2)\n",
    "# The specific feature extractor depends on the model. For Wav2Vec2/WavLM, it mainly handles\n",
    "# resampling and tokenization if needed, but often just converts to the correct format.\n",
    "# We'll use a generic one first and specific ones when defining models.\n",
    "# For Wav2Vec2, input is typically raw audio, which `AutoFeatureExtractor` handles.\n",
    "feature_extractor_w2v2 = AutoFeatureExtractor.from_pretrained(\"facebook/wav2vec2-base\")\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "# Filter out any samples that might have failed loading or processing\n",
    "train_df_filtered = train_df[train_df['filepath'].apply(os.path.exists)]\n",
    "dev_df_filtered = dev_df[dev_df['filepath'].apply(os.path.exists)]\n",
    "eval_df_filtered = eval_df[eval_df['filepath'].apply(os.path.exists)]\n",
    "\n",
    "train_dataset = AudioSpoofDataset(train_df_filtered, feature_extractor_w2v2)\n",
    "dev_dataset = AudioSpoofDataset(dev_df_filtered, feature_extractor_w2v2)\n",
    "eval_dataset = AudioSpoofDataset(eval_df_filtered, feature_extractor_w2v2)\n",
    "\n",
    "BATCH_SIZE = 8 # Adjust based on your GPU memory\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "dev_dataloader = DataLoader(dev_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "print(f\"Number of training batches: {len(train_dataloader)}\")\n",
    "print(f\"Number of development batches: {len(dev_dataloader)}\")\n",
    "print(f\"Number of evaluation batches: {len(eval_dataloader)}\")\n",
    "\n",
    "# Test a single batch\n",
    "for batch in train_dataloader:\n",
    "    print(f\"Input values shape: {batch['input_values'].shape}\")\n",
    "    print(f\"Labels shape: {batch['labels'].shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a09f779-2c90-4086-9607-cfee01c7ef28",
   "metadata": {},
   "source": [
    "## Feature Engineering (for ResNet/CNN Baseline)\n",
    "For the SSL models (Wav2Vec2, WavLM), the raw waveform is the input, and the model itself performs feature extraction. For the ResNet/CNN baseline, we need to explicitly compute Mel-spectrograms. This will be integrated into a separate Dataset class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b93976-405b-41c5-b0d5-2fc49ee1a1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelSpectrogramSpoofDataset(Dataset):\n",
    "    def __init__(self, dataframe, n_mels=80, n_fft=400, hop_length=160, max_length=MAX_AUDIO_LENGTH, sample_rate=TARGET_SAMPLE_RATE):\n",
    "        self.dataframe = dataframe\n",
    "        self.n_mels = n_mels\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "        self.max_length = max_length\n",
    "        self.sample_rate = sample_rate\n",
    "        \n",
    "        self.mel_spectrogram_transform = torchaudio.transforms.MelSpectrogram(\n",
    "            sample_rate=self.sample_rate,\n",
    "            n_fft=self.n_fft,\n",
    "            hop_length=self.hop_length,\n",
    "            n_mels=self.n_mels\n",
    "        )\n",
    "        self.amplitude_to_db_transform = torchaudio.transforms.AmplitudeToDB()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filepath = self.dataframe.iloc[idx]['filepath']\n",
    "        label = self.dataframe.iloc[idx]['label']\n",
    "\n",
    "        try:\n",
    "            waveform, sr = torchaudio.load(filepath)\n",
    "\n",
    "            if sr != self.sample_rate:\n",
    "                resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=self.sample_rate)\n",
    "                waveform = resampler(waveform)\n",
    "\n",
    "            if waveform.shape[0] > 1:\n",
    "                waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "\n",
    "            if waveform.shape[1] < self.max_length:\n",
    "                padding = self.max_length - waveform.shape[1]\n",
    "                waveform = torch.nn.functional.pad(waveform, (0, padding))\n",
    "            else:\n",
    "                waveform = waveform[:, :self.max_length]\n",
    "\n",
    "            mel_spectrogram = self.mel_spectrogram_transform(waveform)\n",
    "            mel_spectrogram_db = self.amplitude_to_db_transform(mel_spectrogram)\n",
    "            \n",
    "            # Ensure the spectrogram has a channel dimension (e.g., [1, n_mels, time_frames]) for CNN input\n",
    "            if mel_spectrogram_db.ndim == 2:\n",
    "                mel_spectrogram_db = mel_spectrogram_db.unsqueeze(0) # Add channel dimension\n",
    "\n",
    "            return {'input_values': mel_spectrogram_db, 'labels': torch.tensor(label, dtype=torch.long)}\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filepath}: {e}. Skipping this sample.\")\n",
    "            return {'input_values': torch.zeros(1, self.n_mels, self.max_length // self.hop_length + 1), 'labels': torch.tensor(-1, dtype=torch.long)}\n",
    "\n",
    "# Create datasets and dataloaders for ResNet\n",
    "train_resnet_dataset = MelSpectrogramSpoofDataset(train_df_filtered)\n",
    "dev_resnet_dataset = MelSpectrogramSpoofDataset(dev_df_filtered)\n",
    "eval_resnet_dataset = MelSpectrogramSpoofDataset(eval_df_filtered)\n",
    "\n",
    "train_resnet_dataloader = DataLoader(train_resnet_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "dev_resnet_dataloader = DataLoader(dev_resnet_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "eval_resnet_dataloader = DataLoader(eval_resnet_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "print(f\"\\nNumber of ResNet training batches: {len(train_resnet_dataloader)}\")\n",
    "for batch in train_resnet_dataloader:\n",
    "    print(f\"ResNet Input values shape: {batch['input_values'].shape}\") # Should be [BATCH_SIZE, 1, n_mels, time_frames]\n",
    "    print(f\"ResNet Labels shape: {batch['labels'].shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e134f1-e7a2-4b9f-8326-66ceef28c652",
   "metadata": {},
   "source": [
    "## Models\n",
    "We will implement three models as specified in the proposal:\n",
    "\n",
    "- Wav2Vec2 (SSL model)\n",
    "- WavLM (SSL model)\n",
    "- ResNet-based CNN (non-SSL baseline)\n",
    "  \n",
    "For Wav2Vec2 and WavLM, we will leverage the transformers library, adding a classification head. For ResNet, we'll define a custom CNN architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b045f4-0a82-42d1-b3b7-487fb8b6359a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Base Class for Training & Evaluation ---\n",
    "class BaseModelTrainer:\n",
    "    def __init__(self, model, dataloaders, optimizer, criterion, device):\n",
    "        self.model = model.to(device)\n",
    "        self.train_loader, self.dev_loader, self.eval_loader = dataloaders\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.device = device\n",
    "        self.history = {'train_loss': [], 'dev_loss': [], 'dev_eer': [], 'dev_asr': []}\n",
    "\n",
    "    def train_epoch(self):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        for batch in tqdm(self.train_loader, desc=\"Training\"):\n",
    "            inputs = batch['input_values'].to(self.device)\n",
    "            labels = batch['labels'].to(self.device)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            # Models from transformers return an output object with 'logits'\n",
    "            if isinstance(self.model, (Wav2Vec2ForSequenceClassification, WavLMForSequenceClassification)):\n",
    "                outputs = self.model(inputs, labels=labels)\n",
    "                loss = outputs.loss\n",
    "            else: # Custom CNN/ResNet\n",
    "                logits = self.model(inputs)\n",
    "                loss = self.criterion(logits, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        return total_loss / len(self.train_loader)\n",
    "\n",
    "    def evaluate(self, dataloader, attack=None, description=\"Evaluation\"):\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        all_labels = []\n",
    "        all_preds = []\n",
    "        all_probs = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(dataloader, desc=description):\n",
    "                inputs = batch['input_values'].to(self.device)\n",
    "                labels = batch['labels'].to(self.device)\n",
    "\n",
    "                # Apply adversarial attack if provided\n",
    "                if attack:\n",
    "                    inputs_adv = attack(inputs, labels) # Attack might need labels\n",
    "                    # Ensure the adversarial attack does not modify original inputs outside this scope\n",
    "                    inputs = inputs_adv.detach() \n",
    "\n",
    "                if isinstance(self.model, (Wav2Vec2ForSequenceClassification, WavLMForSequenceClassification)):\n",
    "                    outputs = self.model(inputs)\n",
    "                    logits = outputs.logits\n",
    "                else:\n",
    "                    logits = self.model(inputs)\n",
    "\n",
    "                loss = self.criterion(logits, labels)\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                probs = torch.softmax(logits, dim=-1)\n",
    "                preds = torch.argmax(probs, dim=-1)\n",
    "\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_probs.extend(probs[:, 1].cpu().numpy()) # Probability of being bona fide\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        \n",
    "        # Calculate EER\n",
    "        fpr, tpr, thresholds = roc_curve(all_labels, all_probs)\n",
    "        eer_threshold = thresholds[np.argmin(np.abs(fpr - (1 - tpr)))]\n",
    "        eer = fpr[np.argmin(np.abs(fpr - (1 - tpr)))] # EER is FPR at threshold where FAR=FRR\n",
    "\n",
    "        # Calculate ASR (Attack Success Rate) - relevant for adversarial evaluation\n",
    "        # For spoofing detection, ASR is when a SPOOF sample is misclassified as BONA FIDE (label 1)\n",
    "        # So, we only consider actual spoof samples (label 0)\n",
    "        spoof_indices = [i for i, label in enumerate(all_labels) if label == 0]\n",
    "        if len(spoof_indices) > 0:\n",
    "            spoof_labels = [all_labels[i] for i in spoof_indices]\n",
    "            spoof_preds = [all_preds[i] for i in spoof_indices]\n",
    "            # ASR: spoof (0) classified as bona_fide (1)\n",
    "            asr = np.sum(np.array(spoof_preds) == 1) / len(spoof_preds)\n",
    "        else:\n",
    "            asr = 0.0 # No spoof samples to attack\n",
    "\n",
    "        # Other metrics\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        f1 = f1_score(all_labels, all_preds)\n",
    "        precision = precision_score(all_labels, all_preds, zero_division=0)\n",
    "        recall = recall_score(all_labels, all_preds, zero_division=0)\n",
    "\n",
    "        print(f\"  {description} Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}, EER: {eer:.4f}, ASR: {asr:.4f}, F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\n",
    "        return avg_loss, eer, asr, accuracy, f1, precision, recall\n",
    "\n",
    "    def fit(self, num_epochs, adv_attack_trainer=None):\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "            if adv_attack_trainer: # Use adversarial training loop\n",
    "                train_loss = adv_attack_trainer.train_epoch_adv()\n",
    "            else: # Standard training\n",
    "                train_loss = self.train_epoch()\n",
    "            \n",
    "            dev_loss, dev_eer, dev_asr, _, _, _, _ = self.evaluate(self.dev_loader, description=\"Development\")\n",
    "            \n",
    "            self.history['train_loss'].append(train_loss)\n",
    "            self.history['dev_loss'].append(dev_loss)\n",
    "            self.history['dev_eer'].append(dev_eer)\n",
    "            self.history['dev_asr'].append(dev_asr) # This ASR would be on clean dev set for baseline\n",
    "\n",
    "            print(f\"Epoch {epoch+1} - Train Loss: {train_loss:.4f}, Dev Loss: {dev_loss:.4f}, Dev EER: {dev_eer:.4f}\")\n",
    "            \n",
    "            # Simple early stopping (can be improved)\n",
    "            # if len(self.history['dev_loss']) > 1 and dev_loss > self.history['dev_loss'][-2]:\n",
    "            #     print(\"Development loss increased, stopping early.\")\n",
    "            #     break\n",
    "        print(\"Training complete.\")\n",
    "\n",
    "# --- Adversarial Training Wrapper ---\n",
    "class AdversarialTrainer(BaseModelTrainer):\n",
    "    def __init__(self, model, dataloaders, optimizer, criterion, device, attack_class, attack_params):\n",
    "        super().__init__(model, dataloaders, optimizer, criterion, device)\n",
    "        self.attack_class = attack_class\n",
    "        self.attack_params = attack_params\n",
    "        \n",
    "    def train_epoch_adv(self):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        # Instantiate the attack for the current model within the training loop\n",
    "        # This is crucial for white-box attacks where the attack needs the model itself\n",
    "        if isinstance(self.model, (Wav2Vec2ForSequenceClassification, WavLMForSequenceClassification)):\n",
    "            # For HuggingFace models, the attack will directly interact with the model's forward pass\n",
    "            pass # Attack is instantiated per batch inside the loop\n",
    "        else: # For custom ResNet, attack needs the module\n",
    "            self.attack = self.attack_class(self.model, **self.attack_params)\n",
    "\n",
    "        for batch in tqdm(self.train_loader, desc=\"Adversarial Training\"):\n",
    "            inputs = batch['input_values'].to(self.device)\n",
    "            labels = batch['labels'].to(self.device)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            # Generate adversarial examples on-the-fly\n",
    "            if isinstance(self.model, (Wav2Vec2ForSequenceClassification, WavLMForSequenceClassification)):\n",
    "                # For transformers models, attacks might need custom wrappers or to be applied to raw inputs\n",
    "                # For simplicity here, we assume attack_class directly takes model, inputs, labels\n",
    "                # A more robust implementation might require a custom attack wrapper for HuggingFace models\n",
    "                attack_instance = self.attack_class(self.model, **self.attack_params)\n",
    "                inputs_adv = attack_instance(inputs, labels)\n",
    "            else:\n",
    "                inputs_adv = self.attack(inputs, labels) # Use pre-instantiated attack for custom models\n",
    "\n",
    "            # Train on adversarial examples\n",
    "            if isinstance(self.model, (Wav2Vec2ForSequenceClassification, WavLMForSequenceClassification)):\n",
    "                outputs = self.model(inputs_adv, labels=labels)\n",
    "                loss = outputs.loss\n",
    "            else:\n",
    "                logits = self.model(inputs_adv)\n",
    "                loss = self.criterion(logits, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        return total_loss / len(self.train_loader)\n",
    "\n",
    "\n",
    "# --- Device Configuration ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- 1. Wav2Vec2 Model ---\n",
    "print(\"\\nInitializing Wav2Vec2 model...\")\n",
    "# Using a pre-trained base model and adding a classification head (num_labels=2 for binary)\n",
    "model_w2v2 = Wav2Vec2ForSequenceClassification.from_pretrained(\n",
    "    \"facebook/wav2vec2-base\",\n",
    "    num_labels=2,\n",
    "    ignore_mismatched_sizes=True # Ignore warnings if head is replaced\n",
    ")\n",
    "# Ensure the feature extractor used for the dataset matches the model's expectations\n",
    "feature_extractor_w2v2 = AutoFeatureExtractor.from_pretrained(\"facebook/wav2vec2-base\")\n",
    "train_dataset_w2v2 = AudioSpoofDataset(train_df_filtered, feature_extractor_w2v2)\n",
    "dev_dataset_w2v2 = AudioSpoofDataset(dev_df_filtered, feature_extractor_w2v2)\n",
    "eval_dataset_w2v2 = AudioSpoofDataset(eval_df_filtered, feature_extractor_w2v2)\n",
    "train_dataloader_w2v2 = DataLoader(train_dataset_w2v2, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "dev_dataloader_w2v2 = DataLoader(dev_dataset_w2v2, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "eval_dataloader_w2v2 = DataLoader(eval_dataset_w2v2, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "\n",
    "optimizer_w2v2 = torch.optim.AdamW(model_w2v2.parameters(), lr=1e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# --- 2. WavLM Model ---\n",
    "print(\"\\nInitializing WavLM model...\")\n",
    "model_wavlm = WavLMForSequenceClassification.from_pretrained(\n",
    "    \"microsoft/wavlm-base\",\n",
    "    num_labels=2,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "feature_extractor_wavlm = AutoFeatureExtractor.from_pretrained(\"microsoft/wavlm-base\")\n",
    "train_dataset_wavlm = AudioSpoofDataset(train_df_filtered, feature_extractor_wavlm)\n",
    "dev_dataset_wavlm = AudioSpoofDataset(dev_df_filtered, feature_extractor_wavlm)\n",
    "eval_dataset_wavlm = AudioSpoofDataset(eval_df_filtered, feature_extractor_wavlm)\n",
    "train_dataloader_wavlm = DataLoader(train_dataset_wavlm, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "dev_dataloader_wavlm = DataLoader(dev_dataset_wavlm, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "eval_dataloader_wavlm = DataLoader(eval_dataset_wavlm, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "optimizer_wavlm = torch.optim.AdamW(model_wavlm.parameters(), lr=1e-5)\n",
    "\n",
    "# --- 3. ResNet-based CNN ---\n",
    "print(\"\\nInitializing ResNet-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5a24a5-45f3-4ceb-956a-3af513dc354a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
