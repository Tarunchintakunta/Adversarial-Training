\section{Methodology}
\label{sec:Methodology}

This section outlines the methodological framework adopted to evaluate and strengthen adversarial robustness in Automatic Speaker Verification (ASV) systems. It integrates signal processing techniques, deep residual learning, and adversarial threat modelling to provide a comprehensive experimental setup.

\subsection{Overview}
This section formally defines the methodology employed to assess and enhance the adversarial robustness of Automatic Speaker Verification (ASV) systems. The framework rests on three pillars: (1) a robust feature extraction pipeline transforming raw audio into time-frequency representations; (2) a Deep Residual Learning architecture (ResNet-18) tailored for identifying spectral artifacts; and (3) a rigorous adversarial threat model incorporating both single-step and iterative gradient-based attacks.

\subsection{Feature Extraction Pipeline}
\label{sec:preprocessing}
The input to the system is a raw audio waveform, $x[n]$, sampled at 16 kHz. To capture the spectral nuances required for distinguishing bona fide speech from synthesized attacks, we convert the 1D signal into a 2D Mel-spectrogram.

\subsubsection{Short-Time Fourier Transform (STFT)}
The non-stationary nature of speech signals necessitates time-frequency analysis. We employ the STFT, computed by windowing the signal into short overlapping frames. Let $w[n]$ be a Hamming window of length $N=400$ (25 ms) and hop size $H=160$ (10 ms). The discrete STFT is given by:
\begin{equation}
    X(m, k) = \sum_{n=0}^{N-1} x[mH + n] w[n] e^{-j\frac{2\pi}{N}kn}
\end{equation}
where $m$ is the frame index and $k$ is the frequency bin index. This transformation maps the signal from the time domain to the complex frequency domain.

\subsubsection{Mel-Filterbank Integration}
The human ear's frequency resolution is logarithmic. To mimic this, we map the power spectrum $|X(m, k)|^2$ onto the Mel scale, which emphasizes lower frequencies over higher ones. The mapping from Hertz ($f$) to Mels ($m$) is defined as:
\begin{equation}
    m = 2595 \log_{10}\left(1 + \frac{f}{700}\right)
\end{equation}
We apply a filterbank of $F=64$ triangular filters spaced equidistantly on the Mel scale. The logarithmic energy of the filterbank outputs forms the Log-Mel Spectrogram $S \in \mathbb{R}^{F \times T}$. This 2D tensor serves as the input image to the convolutional neural network.

\subsection{Deep Residual Learning Architecture}
\label{sec:resnet}
We adopt the ResNet-18 architecture \cite{he2016deep}, widely recognized for its ability to train deep networks without suffering from the vanishing gradient problem.

\subsubsection{The Residual Block}
The core innovation of ResNet is the residual learning framework. Instead of hoping every few stacked layers directly fit a desired underlying mapping $H(x)$, we explicitly let these layers fit a residual mapping $F(x) := H(x) - x$. The original mapping is then recast into $F(x) + x$.
The operation of a fundamental building block can be expressed as:
\begin{equation}
    \mathbf{y} = \sigma(\mathcal{F}(\mathbf{x}, \{W_i\}) + \mathbf{x})
\end{equation}
where $\mathbf{x}$ and $\mathbf{y}$ are the input and output vectors of the layers considered, and $\mathcal{F}$ is the residual function. In our architecture, $\mathcal{F}$ involves two $3\times3$ convolutions, each followed by Batch Normalization (BN) and a Rectified Linear Unit (ReLU) activation function $\sigma(\cdot)$.
The skip connection ($\mathbf{x}$) acts as an identity mapping, ensuring that gradients can flow through the network unimpeded during backpropagation, facilitating the training of deeper models.

\subsubsection{Network Topology}
The ResNet-18 model consists of:
\begin{enumerate}
    \item \textbf{Initial Convolution:} A $7\times7$ conv layer with 64 filters and stride 2, followed by a $3\times3$ max pool.
    \item \textbf{Residual Stages:} Four stages containing pairs of residual blocks with filter sizes [64, 128, 256, 512]. Downsampling is performed by strided convolutions in the first layer of each stage (except the first).
    \item \textbf{Global Average Pooling:} Reduces the spatial dimensions to a feature vector.
    \item \textbf{Fully Connected Layer:} A final linear layer mapping the feature vector to the binary output classes (Spoof vs. Bonafide).
\end{enumerate}

\subsection{Adversarial Threat Modelling}
We simulate a ``White-Box'' attack setting, typically considered the most severe security threat. The adversary has full knowledge of the model parameters $\theta$ and aims to find a perturbation $\delta$ that maximizes the loss $L$, such that the perturbed input $x + \delta$ is misclassified.

\subsubsection{Optimization Objective}
The adversary solves the following constrained optimization problem:
\begin{equation}
    \max_{\delta \in \mathcal{S}} L(\theta, x + \delta, y) \quad \text{s.t.} \quad \|\delta\|_\infty \leq \epsilon
\end{equation}
where $\mathcal{S}$ is the set of allowable perturbations bounded by an $L_\infty$ norm constraint $\epsilon$, ensuring the noise remains imperceptible to human listeners.

\subsubsection{Fast Gradient Sign Method (FGSM)}
FGSM \cite{goodfellow2014explaining} linearizes the loss function around the current input $x$ and takes a single step in the direction of the gradient sign. It is a computationally efficient method for generating adversarial examples.
\begin{equation}
    x_{adv} = x + \epsilon \cdot \text{sign}(\nabla_x L(\theta, x, y))
\end{equation}
While fast, FGSM relies on the assumption of linearity and may not locate the strongest adversary in highly non-linear loss landscapes.

\subsubsection{Projected Gradient Descent (PGD)}
PGD \cite{madry2017towards} is an iterative extension of FGSM. It explores the loss landscape more thoroughly by taking multiple small steps of size $\alpha$. After each step, the perturbation is clipped (projected) to ensure it stays within the $\epsilon$-ball.
\begin{equation}
    x^{t+1} = \Pi_{\epsilon} \left( x^t + \alpha \cdot \text{sign}(\nabla_{x} L(\theta, x^t, y)) \right)
\end{equation}
where $\Pi_{\epsilon}$ denotes the projection operator. We run PGD for $k$ iterations (typically 7--10) to generate strong adversarial examples. Models trained to resist PGD attacks are generally robust against all First-Order adversaries.

\subsection{Summary}
This section presented the methodological foundation of the study. A feature extraction pipeline transforms raw audio into log-mel spectrograms, which are then processed by a ResNet-18 architecture designed to capture spectral artifacts. Finally, adversarial threat modelling was introduced, detailing FGSM and PGD attacks under a white-box setting. Together, these components establish the experimental framework for evaluating the robustness of ASV systems against adversarial perturbations.
